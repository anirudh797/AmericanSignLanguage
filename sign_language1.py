# -*- coding: utf-8 -*-
"""sign_language1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1om2pCYMA934J0ELj73ldvByWazt99MfT
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!!cp kaggle.json ~/.kaggle/

#change the permission
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d datamunge/sign-language-mnist

from zipfile import ZipFile
file_name = "sign-language-mnist.zip"

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

!pip install Keras==2.3.1

import struct
import random
import numpy as np 
import pandas as pd
import tensorflow as tf
import tensorflow.keras as keras
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential



from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
from keras.callbacks import *

import pandas as pd
train_df=pd.read_csv('sign_mnist_train.csv')
test_df=pd.read_csv('sign_mnist_test.csv')
train_df.head()

train_label=train_df['label']
train_label.head()
trainset=train_df.drop(['label'],axis=1)
trainset.head()

X_train = trainset.values
X_train = trainset.values.reshape(-1,28,28,1)
print(X_train.shape)

test_label=test_df['label']
X_test=test_df.drop(['label'],axis=1)
print(X_test.shape)
X_test.head()

from sklearn.preprocessing import LabelBinarizer
lb=LabelBinarizer()
y_train=lb.fit_transform(train_label)
y_test=lb.fit_transform(test_label)

y_train

X_test=X_test.values.reshape(-1,28,28,1)
print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

train_datagen = ImageDataGenerator(rescale = 1./255,
                                  rotation_range = 0,
                                  height_shift_range=0.2,
                                  width_shift_range=0.2,
                                  shear_range=0,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='nearest')

X_test=X_test/255

fig,axe=plt.subplots(2,2)
fig.suptitle('Preview of dataset')
axe[0,0].imshow(X_train[0].reshape(28,28),cmap='gray')
axe[0,0].set_title('label: 3  letter: C')
axe[0,1].imshow(X_train[1].reshape(28,28),cmap='gray')
axe[0,1].set_title('label: 6  letter: F')
axe[1,0].imshow(X_train[2].reshape(28,28),cmap='gray')
axe[1,0].set_title('label: 2  letter: B')
axe[1,1].imshow(X_train[4].reshape(28,28),cmap='gray')
axe[1,1].set_title('label: 13  letter: M')

model=Sequential([])


model=Sequential()
model.add(Conv2D(128,kernel_size=(5,5),
                 strides=1,padding='same',activation='relu',input_shape=(28,28,1)))
model.add(MaxPool2D(pool_size=(3,3),strides=2,padding='same'))
model.add(Conv2D(64,kernel_size=(2,2),
                strides=1,activation='relu',padding='same'))
model.add(MaxPool2D((2,2),2,padding='same'))
model.add(Conv2D(32,kernel_size=(2,2),
                strides=1,activation='relu',padding='same'))
model.add(MaxPool2D((2,2),2,padding='same'))
          
model.add(Flatten())

model.add(Dense(units=512,activation='relu'))
model.add(Dropout(rate=0.25))
model.add(Dense(units=24,activation='softmax'))

model.summary()

model.compile(loss="categorical_crossentropy",optimizer='adam',metrics=['accuracy'])

history=model.fit(train_datagen.flow(X_train,y_train,batch_size=200),
         epochs = 35,
          validation_data=(X_test,y_test),
          shuffle=1
         )

#Plotting training vs Validation loss
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

(ls,acc)=model.evaluate(x=X_test,y=y_test)
print('MODEL ACCURACY = {}%'.format(acc*100))

#American sign language

from google.colab.patches import cv2_imshow
import cv2
cv2.__version__
img=cv2.imread('american_sign_language.PNG',cv2.IMREAD_GRAYSCALE)
plt.figure(figsize = (8,8))
plt.imshow(img , cmap = "gray")

img2=cv2.imread('handsign.png',cv2.IMREAD_COLOR)
cv2_imshow(img2)

#Mapping every aplhabet to integer 0-23 except j and z as they involve motion gesture

letter={0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'K',10:'L',11:'M',12:'N',
        13:'O',14:'P',15:'Q',16:'R',17:'S',18:'T',19:'U',20:'V',21:'W',22:'X',23:'Y'}

predict_class=model.predict(X_test)

fig=plt.figure(figsize=(20,20))


for i in range(0, 25):
  img=X_test[i]
  img=img.reshape(28,28)
  y=fig.add_subplot(5,5,i+1)
  y.imshow(img)
  y.set_title('Prediction = {}\n True = {}\n Letter = {} '.format( np.argmax(predict_class[i]),np.argmax(y_test[i]),letter[np.argmax(y_test[i])]))

  y.axis('off')

plt.subplots_adjust(wspace = 1)

#Saving the model
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive 
from google.colab import auth 
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()                      
drive = GoogleDrive(gauth)

model.save('signlanguage.h5')
model_file = drive.CreateFile({'title' : 'signlanguage.h5'})                       
model_file.SetContentFile('signlanguage.h5')                      
model_file.Upload()

# download to google drive                       
drive.CreateFile({'id': model_file.get('id')})











# Soon will be adding webcam to label hand sign in real time

# #For using webcam to predict output


# from IPython.display import display, Javascript
# from google.colab.output import eval_js
# from base64 import b64decode

# def take_photo(filename='photo.jpg', quality=0.8):
#   js = Javascript('''
#     async function takePhoto(quality) {
#       const div = document.createElement('div');
#       const capture = document.createElement('button');
#       capture.textContent = 'Capture';
#       div.appendChild(capture);

#       const video = document.createElement('video');
#       video.style.display = 'block';
#       const stream = await navigator.mediaDevices.getUserMedia({video: true});

#       document.body.appendChild(div);
#       div.appendChild(video);
#       video.srcObject = stream;
#       await video.play();

#       // Resize the output to fit the video element.
#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

#       // Wait for Capture to be clicked.
#       await new Promise((resolve) => capture.onclick = resolve);

#       const canvas = document.createElement('canvas');
#       canvas.width = video.videoWidth;
#       canvas.height = video.videoHeight;
#       canvas.getContext('2d').drawImage(video, 0, 0);
#       stream.getVideoTracks()[0].stop();
#       div.remove();
#       return canvas.toDataURL('image/jpeg', quality);
#     }
#     ''')
#   display(js)
#   data = eval_js('takePhoto({})'.format(quality))
#   binary = b64decode(data.split(',')[1])
#   with open(filename, 'wb') as f:
#     f.write(binary)
#   return filename

# from IPython.display import Image
# try:
#   filename = take_photo()
#   print('Saved to {}'.format(filename))
  
#   # Show the image which was just taken.
#   display(Image(filename))
# except Exception as err:
#   # Errors will be thrown if the user does not have a webcam or if they do not
#   # grant the page permission to access it.
#   print(str(err))



# from google.colab.patches import cv2_imshow
# import cv2
# cv2.__version__
# img=cv2.imread('american_sign_language.PNG',cv2.IMREAD_GRAYSCALE)
# plt.figure(figsize = (8,8))
# plt.imshow(img , cmap = "gray")

# img=cv2.resize(img,(28,28))
# img=img.reshape(-1,28,28,1)
# img.shape

# v=img
# plt.figure(figsize = (2,2))
# plt.imshow(v.reshape(28,28) , cmap = "gray")

# predict_class=model.predict(img)
# np.argmax(predict_class)
# # fig=plt.figure(figsize=(20,20))
# # img=img.reshape(28,28)
# # y.imshow(img)
# # y.set_title('Prediction = {}\n True = {}'.format(predict_class))

